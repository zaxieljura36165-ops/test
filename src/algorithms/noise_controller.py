"""
æƒ…å¢ƒæ„ŸçŸ¥è‡ªé€‚åº”å™ªå£°æ§åˆ¶å™¨ - ä»»åŠ¡å¸è½½åœºæ™¯ç‰ˆæœ¬

æ ¸å¿ƒåˆ›æ–°ï¼š
1. å…¨å±€æ§åˆ¶ï¼šæ ¹æ®è®­ç»ƒé˜¶æ®µï¼ˆæˆåŠŸç‡ï¼‰åŠ¨æ€è°ƒæ•´åŸºç¡€å™ªå£°å¼ºåº¦
2. å±€éƒ¨æ§åˆ¶ï¼šæ ¹æ®å½“å‰ä»»åŠ¡æƒ…å¢ƒï¼ˆè´Ÿè½½ã€ä¼˜å…ˆçº§ã€ä¿¡é“ç­‰ï¼‰å¾®è°ƒå™ªå£°å¼ºåº¦
3. åŒç¼“å†²åŒºï¼šåˆ†ç¦»æ¢ç´¢æ€§ç»éªŒå’Œç¡®å®šæ€§ç»éªŒï¼Œå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨

æƒ…å¢ƒåˆ†ç±»ï¼ˆä»»åŠ¡å¸è½½åœºæ™¯ï¼‰ï¼š
- high_load: ç³»ç»Ÿé«˜è´Ÿè½½ï¼Œé«˜å™ªå£°æ¢ç´¢æ›´ä¼˜å¸è½½ç­–ç•¥
- low_load: ç³»ç»Ÿä½è´Ÿè½½ï¼Œä½å™ªå£°ç¨³å®šæ‰§è¡Œ
- urgent_task: ç´§æ€¥ä»»åŠ¡ï¼Œä¸­ä½å™ªå£°ç¡®ä¿æ—¶æ•ˆ
- normal_task: æ™®é€šä»»åŠ¡ï¼Œä¸­ç­‰å™ªå£°
- congested_network: ç½‘ç»œæ‹¥å¡ï¼Œè¾ƒé«˜å™ªå£°æ¢ç´¢æ›¿ä»£æ–¹æ¡ˆ
- good_channel: è‰¯å¥½ä¿¡é“ï¼Œä½å™ªå£°å……åˆ†åˆ©ç”¨
- near_deadline: æ¥è¿‘æˆªæ­¢æ—¶é—´ï¼Œä½å™ªå£°ç¨³å®šå†³ç­–
- high_priority: é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œä¸­ä½å™ªå£°
"""

import numpy as np
import torch
from collections import deque
from typing import Dict, Any, List, Tuple, Optional


class TaskOffloadNoiseController:
    """
    ä»»åŠ¡å¸è½½åœºæ™¯çš„æƒ…å¢ƒæ„ŸçŸ¥å™ªå£°æ§åˆ¶å™¨
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. è®­ç»ƒé˜¶æ®µæ§åˆ¶ï¼šPhase1éšæœºæ¢ç´¢ â†’ Phase2å¢å¼ºæ¢ç´¢ â†’ Phase3ç¨³å®šå¾®è°ƒ
    2. æƒ…å¢ƒæ„ŸçŸ¥ï¼šæ ¹æ®ä»»åŠ¡å±æ€§å’Œç³»ç»ŸçŠ¶æ€åŠ¨æ€è°ƒæ•´å™ªå£°
    3. å™ªå£°åªé™ä¸å‡ï¼šPhaseåªèƒ½å‡çº§ä¸èƒ½é™çº§ï¼Œé¿å…ç­–ç•¥é€€åŒ–æ—¶å™ªå£°æš´å¢
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        # ========== å…¨å±€å™ªå£°æ§åˆ¶å‚æ•° ==========
        self.phase = 1  # å½“å‰è®­ç»ƒé˜¶æ®µ
        
        # é˜¶æ®µè½¬æ¢é˜ˆå€¼
        self.phase1_episodes = 50           # å‰50è½®å®Œå…¨éšæœºæ¢ç´¢
        self.phase2_min_episodes = 50      # Phase2æœ€å°æŒç»­è½®æ•°ï¼Œé˜²æ­¢ç›´æ¥è·³åˆ°Phase3
        self.phase2_threshold = 0.3         # æˆåŠŸç‡è¾¾åˆ°30%è¿›å…¥é˜¶æ®µ2
        self.phase3_threshold = 0.6         # æˆåŠŸç‡è¾¾åˆ°60%è¿›å…¥é˜¶æ®µ3
        
        # å…¨å±€å™ªå£°å¼ºåº¦
        self.global_noise_phase1 = 0.8      # é˜¶æ®µ1ï¼šé«˜å™ªå£°
        self.global_noise_phase2_base = 0.4 # é˜¶æ®µ2ï¼šåŸºç¡€å™ªå£°
        self.global_noise_phase3_start = 0.15  # é˜¶æ®µ3ï¼šèµ·å§‹å™ªå£°
        self.global_noise_min = 0.02        # æœ€å°å™ªå£°
        self.global_noise_phase3_decay = 0.9998  # é˜¶æ®µ3è¡°å‡ç‡
        
        # Phase 3 åŠ¨æ€å™ªå£°è·Ÿè¸ª
        self.phase3_current_noise = self.global_noise_phase3_start
        self.phase3_start_episode = None
        
        # ========== æƒ…å¢ƒå™ªå£°æ§åˆ¶å‚æ•°ï¼ˆä»»åŠ¡å¸è½½åœºæ™¯ï¼‰==========
        self.context_noise_factors = {
            'high_load': 0.8,           # é«˜è´Ÿè½½ï¼šè¾ƒé«˜å™ªå£°ï¼Œæ¢ç´¢æ›´ä¼˜å¸è½½ç­–ç•¥
            'low_load': 0.3,            # ä½è´Ÿè½½ï¼šä½å™ªå£°ï¼Œç¨³å®šæ‰§è¡Œ
            'urgent_task': 0.4,         # ç´§æ€¥ä»»åŠ¡ï¼šä¸­ä½å™ªå£°ï¼Œç¡®ä¿æ—¶æ•ˆ
            'normal_task': 0.6,         # æ™®é€šä»»åŠ¡ï¼šä¸­ç­‰å™ªå£°
            'congested_network': 0.7,   # ç½‘ç»œæ‹¥å¡ï¼šè¾ƒé«˜å™ªå£°ï¼Œæ¢ç´¢æ›¿ä»£æ–¹æ¡ˆ
            'good_channel': 0.3,        # è‰¯å¥½ä¿¡é“ï¼šä½å™ªå£°ï¼Œå……åˆ†åˆ©ç”¨
            'near_deadline': 0.3,       # æ¥è¿‘æˆªæ­¢æ—¶é—´ï¼šä½å™ªå£°ï¼Œç¨³å®šå†³ç­–
            'high_priority': 0.4,       # é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼šä¸­ä½å™ªå£°
            'default': 0.5,             # é»˜è®¤æƒ…å¢ƒ
        }
        
        # æƒ…å¢ƒåˆ¤æ–­é˜ˆå€¼
        self.high_load_threshold = 0.7      # é˜Ÿåˆ—è´Ÿè½½ > 70%
        self.low_load_threshold = 0.3       # é˜Ÿåˆ—è´Ÿè½½ < 30%
        self.urgent_priority_threshold = 0.7    # ä¼˜å…ˆçº§ > 0.7
        self.near_deadline_ratio = 0.3      # å‰©ä½™æ—¶é—´/æˆªæ­¢æ—¶é—´ < 30%
        self.good_channel_threshold = 0.6   # ä¿¡é“è´¨é‡ > 0.6
        self.congested_threshold = 0.8      # è¾¹ç¼˜èŠ‚ç‚¹è´Ÿè½½ > 80%
        
        # ========== ç»Ÿè®¡ä¿¡æ¯ ==========
        self.success_history = deque(maxlen=100)
        self.current_episode = 0
        self.current_success_rate = 0.0
        
        # æƒ…å¢ƒç»Ÿè®¡
        self.context_counts = {k: 0 for k in self.context_noise_factors.keys()}
        
        # åº”ç”¨é…ç½®
        if config is not None:
            self._apply_config(config)
    
    def _apply_config(self, config: Dict[str, Any]):
        """ä»é…ç½®å­—å…¸åŠ è½½å‚æ•°"""
        if 'phase1_episodes' in config:
            self.phase1_episodes = config['phase1_episodes']
        if 'phase2_min_episodes' in config:
            self.phase2_min_episodes = config['phase2_min_episodes']
        if 'phase2_threshold' in config:
            self.phase2_threshold = config['phase2_threshold']
        if 'phase3_threshold' in config:
            self.phase3_threshold = config['phase3_threshold']
        if 'phase1_noise' in config:
            self.global_noise_phase1 = config['phase1_noise']
        if 'phase2_base_noise' in config:
            self.global_noise_phase2_base = config['phase2_base_noise']
        if 'phase3_start_noise' in config:
            self.global_noise_phase3_start = config['phase3_start_noise']
            self.phase3_current_noise = config['phase3_start_noise']
        if 'min_noise' in config:
            self.global_noise_min = config['min_noise']
        if 'phase3_decay' in config:
            self.global_noise_phase3_decay = config['phase3_decay']
        if 'context_noise_factors' in config:
            self.context_noise_factors.update(config['context_noise_factors'])
        
        # æƒ…å¢ƒé˜ˆå€¼
        if 'high_load_threshold' in config:
            self.high_load_threshold = config['high_load_threshold']
        if 'low_load_threshold' in config:
            self.low_load_threshold = config['low_load_threshold']
        if 'urgent_priority_threshold' in config:
            self.urgent_priority_threshold = config['urgent_priority_threshold']
        if 'near_deadline_ratio' in config:
            self.near_deadline_ratio = config['near_deadline_ratio']
        if 'good_channel_threshold' in config:
            self.good_channel_threshold = config['good_channel_threshold']
    
    def update_training_stats(self, episode: int, is_success: bool):
        """
        æ›´æ–°è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        æ¯ä¸ªepisodeç»“æŸæ—¶è°ƒç”¨
        """
        self.current_episode = episode
        self.success_history.append(1 if is_success else 0)
        
        if len(self.success_history) > 0:
            self.current_success_rate = np.mean(self.success_history)
        
        self._update_phase()
    
    def _update_phase(self):
        """æ ¹æ®è®­ç»ƒè¿›åº¦æ›´æ–°é˜¶æ®µ - Phaseåªèƒ½å‡ä¸èƒ½é™"""
        old_phase = self.phase
        
        # è®¡ç®—ç›®æ ‡Phase
        if self.current_episode < self.phase1_episodes:
            target_phase = 1
        elif self.current_episode < self.phase1_episodes + self.phase2_min_episodes:
            target_phase = 2
        elif self.current_success_rate < self.phase2_threshold:
            target_phase = 2
        elif self.current_success_rate < self.phase3_threshold:
            target_phase = 2
        else:
            target_phase = 3
        
        # Phaseåªèƒ½å‡ä¸èƒ½é™
        if target_phase > self.phase:
            self.phase = target_phase
        
        if old_phase != self.phase:
            print(f"ğŸ”„ å™ªå£°æ§åˆ¶é˜¶æ®µåˆ‡æ¢: Phase {old_phase} â†’ Phase {self.phase} "
                  f"(Episode: {self.current_episode}, Success Rate: {self.current_success_rate:.2%})")
            
            if self.phase == 3 and old_phase != 3:
                self.phase3_start_episode = self.current_episode
                self.phase3_current_noise = self.global_noise_phase3_start
                print(f"ğŸ“‰ Phase 3 å™ªå£°å°†ä» {self.global_noise_phase3_start:.3f} æŒç»­è¡°å‡åˆ° {self.global_noise_min:.3f}")
    
    def get_global_noise_factor(self) -> float:
        """
        è·å–å…¨å±€å™ªå£°å› å­
        è¿”å›å€¼èŒƒå›´: [global_noise_min, 1]
        """
        if self.phase == 1:
            return self.global_noise_phase1
        elif self.phase == 2:
            progress = min(1.0, self.current_success_rate / self.phase3_threshold)
            noise = self.global_noise_phase2_base * (1.0 - 0.5 * progress)
            return max(self.global_noise_phase3_start, noise)
        else:
            # Phase 3ï¼šæŒç»­è¡°å‡
            self.phase3_current_noise *= self.global_noise_phase3_decay
            self.phase3_current_noise = max(self.phase3_current_noise, self.global_noise_min)
            return self.phase3_current_noise
    
    def classify_context(self, context_info: Dict[str, Any]) -> str:
        """
        æ ¹æ®ä»»åŠ¡å’Œç³»ç»ŸçŠ¶æ€åˆ¤æ–­å½“å‰æƒ…å¢ƒ
        
        Args:
            context_info: æƒ…å¢ƒä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
                - queue_load: é˜Ÿåˆ—è´Ÿè½½ [0, 1]
                - task_priority: ä»»åŠ¡ä¼˜å…ˆçº§ [0, 1]
                - deadline_ratio: å‰©ä½™æ—¶é—´/æˆªæ­¢æ—¶é—´ [0, 1]
                - channel_quality: ä¿¡é“è´¨é‡ [0, 1]
                - edge_load: è¾¹ç¼˜èŠ‚ç‚¹è´Ÿè½½ [0, 1]
        
        Returns:
            context: æƒ…å¢ƒç±»å‹å­—ç¬¦ä¸²
        """
        queue_load = context_info.get('queue_load', 0.5)
        task_priority = context_info.get('task_priority', 0.5)
        deadline_ratio = context_info.get('deadline_ratio', 0.5)
        channel_quality = context_info.get('channel_quality', 0.5)
        edge_load = context_info.get('edge_load', 0.5)
        
        # ========== æƒ…å¢ƒåˆ†ç±»é€»è¾‘ ==========
        
        # 1. æ¥è¿‘æˆªæ­¢æ—¶é—´ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if deadline_ratio < self.near_deadline_ratio:
            context = 'near_deadline'
        
        # 2. é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        elif task_priority > self.urgent_priority_threshold:
            context = 'high_priority'
        
        # 3. ç´§æ€¥ä»»åŠ¡ï¼ˆä¼˜å…ˆçº§é«˜ä¸”æ—¶é—´ç´§ï¼‰
        elif task_priority > 0.5 and deadline_ratio < 0.5:
            context = 'urgent_task'
        
        # 4. ç½‘ç»œæ‹¥å¡
        elif edge_load > self.congested_threshold:
            context = 'congested_network'
        
        # 5. ç³»ç»Ÿé«˜è´Ÿè½½
        elif queue_load > self.high_load_threshold:
            context = 'high_load'
        
        # 6. è‰¯å¥½ä¿¡é“
        elif channel_quality > self.good_channel_threshold and edge_load < 0.5:
            context = 'good_channel'
        
        # 7. ç³»ç»Ÿä½è´Ÿè½½
        elif queue_load < self.low_load_threshold:
            context = 'low_load'
        
        # 8. é»˜è®¤ï¼šæ™®é€šä»»åŠ¡
        else:
            context = 'normal_task'
        
        # æ›´æ–°ç»Ÿè®¡
        self.context_counts[context] += 1
        
        return context
    
    def get_noise_scale(self, context_info: Dict[str, Any] = None) -> float:
        """
        è·å–å½“å‰æ­¥çš„å™ªå£°å¼ºåº¦
        
        Args:
            context_info: æƒ…å¢ƒä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            noise_scale: å™ªå£°å¼ºåº¦ [0, 1]
        """
        # é˜¶æ®µ1ï¼šè¿”å›æœ€å¤§å™ªå£°
        if self.phase == 1:
            return self.global_noise_phase1
        
        # è·å–å…¨å±€å™ªå£°å› å­
        global_factor = self.get_global_noise_factor()
        
        # å¦‚æœæ²¡æœ‰æƒ…å¢ƒä¿¡æ¯ï¼Œè¿”å›å…¨å±€å™ªå£°
        if context_info is None:
            return global_factor
        
        # åˆ†ç±»å½“å‰æƒ…å¢ƒ
        context = self.classify_context(context_info)
        
        # è·å–æƒ…å¢ƒå™ªå£°å› å­
        context_factor = self.context_noise_factors.get(context, 0.5)
        
        # æœ€ç»ˆå™ªå£° = å…¨å±€å› å­ Ã— æƒ…å¢ƒå› å­
        noise_scale = global_factor * context_factor
        
        # é™åˆ¶èŒƒå›´ï¼šç¡®ä¿æ°¸è¿œä¸ä½äº 0.1ï¼Œé˜²æ­¢æ¢ç´¢è¿‡æ—©åœæ­¢
        noise_scale = np.clip(noise_scale, 0.1, 1.0)
        
        return noise_scale
    
    def should_use_random_action(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å®Œå…¨éšæœºåŠ¨ä½œï¼ˆä»…Phase1ï¼‰"""
        return self.phase == 1
    
    def get_deterministic_ratio(self) -> float:
        """
        è·å–ç¡®å®šæ€§ç»éªŒçš„é‡‡æ ·æ¯”ä¾‹
        ç”¨äºåŒç¼“å†²åŒºé‡‡æ ·
        
        Returns:
            ratio: ç¡®å®šæ€§ç»éªŒå æ¯”
        """
        det_min = 0.1
        det_max = 0.4
        
        if self.phase == 1:
            return 0.0
        elif self.phase == 2:
            progress = min(1.0, self.current_success_rate / self.phase3_threshold)
            return det_min + (det_max - det_min) * 0.5 * progress
        else:
            return det_max
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if self.phase == 3:
            current_noise = self.phase3_current_noise
        else:
            current_noise = self.get_global_noise_factor()
        
        return {
            'phase': self.phase,
            'episode': self.current_episode,
            'success_rate': self.current_success_rate,
            'global_noise': current_noise,
            'min_noise': self.global_noise_min,
            'context_counts': dict(self.context_counts)
        }
    
    def reset_episode(self):
        """æ¯ä¸ªepisodeå¼€å§‹æ—¶é‡ç½®ï¼ˆå¦‚éœ€è¦ï¼‰"""
        pass


class DualReplayBuffer:
    """
    åŒç»éªŒå›æ”¾ç¼“å†²åŒº
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - buffer_noisy: å­˜å‚¨å¸¦æ¢ç´¢å™ªå£°çš„åŠ¨ä½œäº§ç”Ÿçš„ç»éªŒ
    - buffer_deterministic: å­˜å‚¨ç¡®å®šæ€§åŠ¨ä½œäº§ç”Ÿçš„ç»éªŒ
    
    é‡‡æ ·ç­–ç•¥ï¼š
    - è®­ç»ƒæ—©æœŸï¼šä¸»è¦ä»noisy bufferé‡‡æ ·ï¼Œé¼“åŠ±æ¢ç´¢
    - è®­ç»ƒåæœŸï¼šå¢åŠ deterministic bufferé‡‡æ ·ï¼Œç¨³å®šç­–ç•¥
    """
    
    def __init__(self, capacity: int, state_dim: int = None, action_dim: int = None):
        self.capacity = capacity
        self.state_dim = state_dim
        self.action_dim = action_dim
        
        # åŒç¼“å†²åŒº
        self.buffer_noisy = []
        self.buffer_deterministic = []
        self.pos_noisy = 0
        self.pos_deterministic = 0
    
    def push(self, state, action, reward, next_state, done,
             global_state=None, next_global_state=None, is_noisy: bool = True):
        """
        æ·»åŠ ç»éªŒ
        
        Args:
            state: å±€éƒ¨çŠ¶æ€
            action: åŠ¨ä½œï¼ˆå­—å…¸ï¼‰
            reward: å¥–åŠ±
            next_state: ä¸‹ä¸€çŠ¶æ€
            done: æ˜¯å¦ç»“æŸ
            global_state: å…¨å±€çŠ¶æ€ï¼ˆå¯é€‰ï¼ŒCTDEç”¨ï¼‰
            next_global_state: ä¸‹ä¸€å…¨å±€çŠ¶æ€
            is_noisy: æ˜¯å¦ä¸ºæ¢ç´¢æ€§ç»éªŒ
        """
        experience = {
            'state': state,
            'action': action,
            'reward': reward,
            'next_state': next_state,
            'done': done,
            'global_state': global_state,
            'next_global_state': next_global_state
        }
        
        if is_noisy:
            if len(self.buffer_noisy) < self.capacity:
                self.buffer_noisy.append(experience)
            else:
                self.buffer_noisy[self.pos_noisy] = experience
            self.pos_noisy = (self.pos_noisy + 1) % self.capacity
        else:
            if len(self.buffer_deterministic) < self.capacity:
                self.buffer_deterministic.append(experience)
            else:
                self.buffer_deterministic[self.pos_deterministic] = experience
            self.pos_deterministic = (self.pos_deterministic + 1) % self.capacity
    
    def sample(self, batch_size: int, device: torch.device,
               deterministic_ratio: float = 0.3) -> Dict[str, torch.Tensor]:
        """
        ä»åŒç¼“å†²åŒºé‡‡æ ·
        
        Args:
            batch_size: æ‰¹å¤§å°
            device: torchè®¾å¤‡
            deterministic_ratio: ç¡®å®šæ€§ç»éªŒé‡‡æ ·æ¯”ä¾‹
        
        Returns:
            æ‰¹æ¬¡æ•°æ®å­—å…¸
        """
        # è®¡ç®—å„ç¼“å†²åŒºé‡‡æ ·æ•°é‡
        n_deterministic = int(batch_size * deterministic_ratio)
        n_noisy = batch_size - n_deterministic
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ ·æœ¬
        n_deterministic = min(n_deterministic, len(self.buffer_deterministic))
        n_noisy = batch_size - n_deterministic
        n_noisy = min(n_noisy, len(self.buffer_noisy))
        
        if n_noisy + n_deterministic < batch_size:
            n_noisy = min(batch_size, len(self.buffer_noisy))
            n_deterministic = 0
        
        # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œè¿”å›None
        if n_noisy + n_deterministic == 0:
            return None
        
        samples = []
        
        # ä»noisy bufferé‡‡æ ·
        if n_noisy > 0 and len(self.buffer_noisy) > 0:
            indices_noisy = np.random.choice(len(self.buffer_noisy), n_noisy, replace=False)
            for idx in indices_noisy:
                samples.append(self.buffer_noisy[idx])
        
        # ä»deterministic bufferé‡‡æ ·
        if n_deterministic > 0 and len(self.buffer_deterministic) > 0:
            indices_det = np.random.choice(len(self.buffer_deterministic), n_deterministic, replace=False)
            for idx in indices_det:
                samples.append(self.buffer_deterministic[idx])
        
        # è§£åŒ…æ•°æ®
        states = []
        actions = []
        rewards = []
        next_states = []
        dones = []
        global_states = []
        next_global_states = []
        
        for exp in samples:
            # ç¡®ä¿stateæ˜¯numpyæ•°ç»„ä¸”æœ‰æ­£ç¡®å½¢çŠ¶
            state = exp['state']
            next_state = exp['next_state']
            
            if isinstance(state, np.ndarray) and state.size > 0:
                states.append(state.flatten())
            elif isinstance(state, (list, tuple)) and len(state) > 0:
                states.append(np.array(state).flatten())
            else:
                continue  # è·³è¿‡æ— æ•ˆæ ·æœ¬
            
            if isinstance(next_state, np.ndarray) and next_state.size > 0:
                next_states.append(next_state.flatten())
            elif isinstance(next_state, (list, tuple)) and len(next_state) > 0:
                next_states.append(np.array(next_state).flatten())
            else:
                states.pop()  # ç§»é™¤åˆšæ·»åŠ çš„state
                continue
            
            actions.append(exp['action'])
            rewards.append(exp['reward'])
            dones.append(float(exp['done']))
            
            if exp['global_state'] is not None:
                gs = exp['global_state']
                if isinstance(gs, np.ndarray) and gs.size > 0:
                    global_states.append(gs.flatten())
                elif isinstance(gs, (list, tuple)) and len(gs) > 0:
                    global_states.append(np.array(gs).flatten())
            
            if exp['next_global_state'] is not None:
                ngs = exp['next_global_state']
                if isinstance(ngs, np.ndarray) and ngs.size > 0:
                    next_global_states.append(ngs.flatten())
                elif isinstance(ngs, (list, tuple)) and len(ngs) > 0:
                    next_global_states.append(np.array(ngs).flatten())
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ ·æœ¬
        if len(states) == 0:
            return None
        
        # è½¬æ¢ä¸ºå¼ é‡
        batch = {
            'states': torch.FloatTensor(np.stack(states)).to(device),
            'actions': actions,  # ä¿æŒä¸ºåˆ—è¡¨ï¼ˆå› ä¸ºæ˜¯å­—å…¸ï¼‰
            'rewards': torch.FloatTensor(np.array(rewards)).unsqueeze(1).to(device),
            'next_states': torch.FloatTensor(np.stack(next_states)).to(device),
            'dones': torch.FloatTensor(np.array(dones)).unsqueeze(1).to(device),
        }
        
        if global_states and len(global_states) == len(states):
            batch['global_states'] = torch.FloatTensor(np.stack(global_states)).to(device)
        if next_global_states and len(next_global_states) == len(states):
            batch['next_global_states'] = torch.FloatTensor(np.stack(next_global_states)).to(device)
        
        return batch
    
    def __len__(self):
        return len(self.buffer_noisy) + len(self.buffer_deterministic)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å†²åŒºç»Ÿè®¡"""
        return {
            'noisy_size': len(self.buffer_noisy),
            'deterministic_size': len(self.buffer_deterministic),
            'total_size': len(self)
        }


def build_context_info_from_state(state: torch.Tensor, task_info: Dict = None,
                                   queue_manager=None, comm_model=None) -> Dict[str, Any]:
    """
    ä»çŠ¶æ€å’Œä»»åŠ¡ä¿¡æ¯æ„å»ºæƒ…å¢ƒä¿¡æ¯
    
    è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºä»ç¯å¢ƒçŠ¶æ€æ„å»ºå™ªå£°æ§åˆ¶å™¨éœ€è¦çš„æƒ…å¢ƒä¿¡æ¯
    
    Args:
        state: çŠ¶æ€å¼ é‡
        task_info: ä»»åŠ¡ä¿¡æ¯å­—å…¸
        queue_manager: é˜Ÿåˆ—ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        comm_model: é€šä¿¡æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        context_info: æƒ…å¢ƒä¿¡æ¯å­—å…¸
    """
    context_info = {
        'queue_load': 0.5,
        'task_priority': 0.5,
        'deadline_ratio': 0.5,
        'channel_quality': 0.5,
        'edge_load': 0.5,
    }
    
    # ä»ä»»åŠ¡ä¿¡æ¯æå–
    if task_info is not None:
        context_info['task_priority'] = task_info.get('priority', 0.5)
        
        # è®¡ç®—æˆªæ­¢æ—¶é—´æ¯”ä¾‹
        if 'deadline' in task_info and 'arrival_time' in task_info and 'current_time' in task_info:
            remaining = task_info['deadline'] - (task_info['current_time'] - task_info['arrival_time'])
            context_info['deadline_ratio'] = max(0, remaining / task_info['deadline'])
    
    # ä»é˜Ÿåˆ—ç®¡ç†å™¨æå–
    if queue_manager is not None:
        try:
            status = queue_manager.get_global_queue_status()
            total_load = 0
            count = 0
            for vid, vstatus in status.get('vehicles', {}).items():
                total_load += vstatus.get('hpc_length', 0) + vstatus.get('lpc_length', 0)
                count += 1
            if count > 0:
                context_info['queue_load'] = min(1.0, total_load / (count * 10))  # å‡è®¾æ¯ä¸ªé˜Ÿåˆ—å®¹é‡10
            
            # è¾¹ç¼˜èŠ‚ç‚¹è´Ÿè½½
            edge_load = 0
            edge_count = 0
            for eid, estatus in status.get('edges', {}).items():
                edge_load += estatus.get('enc_length', 0)
                edge_count += 1
            if edge_count > 0:
                context_info['edge_load'] = min(1.0, edge_load / (edge_count * 20))
        except:
            pass
    
    # ä»é€šä¿¡æ¨¡å‹æå–ä¿¡é“è´¨é‡
    if comm_model is not None:
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿¡é“è´¨é‡çš„æå–é€»è¾‘
            pass
        except:
            pass
    
    return context_info
