# Hierarchical TD3 架构图绘制指示文档

> **文档版本**: v3.0 — 2026-02-16  
> **对应源码**: `td3_networks.py`, `noise_controller.py`, `hierarchical_td3.py`, `td3_config.py`, `system_config.py`  
> **本文档用途**: 作为绘制算法架构图的唯一权威参考，所有细节均已与代码逐行核对

---

## 一、完整嵌套层次结构

### 1.1 最外层框架（Level 0 → Level 1）

整张图包含 **2 个顶层模块**（Level 1），一个是智能体，一个是环境：

```
┌─────────────────────────────────────────────────────────────┐
│               Hierarchical TD3 Agent                        │ ← Level 1: 顶层模块 A
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  High-Level TD3                                     │   │ ← Level 2
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Low-Level TD3  (V2I / V2V / Local 三组并列)         │   │ ← Level 2
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Context-Aware Adaptive Noise Controller            │   │ ← Level 2
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Dual Replay Buffer  (B_E + B_D)                    │   │ ← Level 2
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│            V2X Task Offloading Environment                  │ ← Level 1: 顶层模块 B
└─────────────────────────────────────────────────────────────┘
```

**关键层级关系**：
- **Level 1 的 Agent 包含 4 个 Level 2 子模块**（High-Level TD3 / Low-Level TD3 / Noise Controller / Dual Buffer）
- **Level 1 的 Environment 与 Agent 平级**，在 Agent 外部
- High-Level TD3 **指挥** Low-Level TD3（上下级关系）
- Noise Controller **辅助** 所有 Actor 输出（侧向辅助关系）
- Dual Buffer **服务** 所有 Critic 训练（底层支撑关系）

---

### 1.2 逐层展开（Level 2 → Level 3 → Level 4）

#### Level 2-A: **High-Level TD3**（高层决策器）

| Level 3 子网络 | 包含的 Level 4 元素 |
|---|---|
| ① Online Actor (`HighLevelTD3Actor`) | MLP: 200→256(LN+ReLU)→256(LN+ReLU)→128(LN+ReLU)→**4** |
| ② Online Critic - Dual-Q (`HighLevelTD3Critic`) | Q1 网络 + Q2 网络，各 (200+4)→256(LN+ReLU)→256(LN+ReLU)→1 |
| ③ Target Actor | 结构同①，通过软更新 τ=0.005 同步 |
| ④ Target Critic - Dual-Q | 结构同②，通过软更新 τ=0.005 同步 |

> ⚠️ **action_dim = 4**（非3）：`HighLevelTD3Actor` 硬编码 `super().__init__(state_dim, 4, ...)`，输出4维 = [α(1维), V2I_logit(1维), V2V_logit(1维), p_base(1维)]。`td3_config.py` 注释中 `action_dim: 3` 是对"3个语义决策"的描述，实际网络输出为 **4维**（因 mode_logits 占2维）。

---

#### Level 2-B: **Low-Level TD3**（低层执行器，包含3个并列 Level 3 子组）

##### Level 3-B1: V2I Scheduler TD3

| Level 4 子网络 | 结构 |
|---|---|
| Online Actor (`V2ISchedulerTD3Actor`) | 200→128(LN+ReLU)→128(LN+ReLU)→**6** [5个RSU_logits + 1个power] |
| Online Critic - Dual-Q (`TD3Critic`) | (200+6)→128(LN+ReLU)→128(LN+ReLU)→1, ×2条 |
| Target Actor | 结构同 Online Actor，软更新 τ=0.005 |
| Target Critic - Dual-Q | 结构同 Online Critic，软更新 τ=0.005 |

##### Level 3-B2: V2V Scheduler TD3

| Level 4 子网络 | 结构 |
|---|---|
| Online Actor (`V2VSchedulerTD3Actor`) | 200→128(LN+ReLU)→128(LN+ReLU)→**6** [5个Neighbor_logits + 1个power] |
| Online Critic - Dual-Q (`TD3Critic`) | (200+6)→128(LN+ReLU)→128(LN+ReLU)→1, ×2条 |
| Target Actor | 结构同 Online Actor，软更新 τ=0.005 |
| Target Critic - Dual-Q | 结构同 Online Critic，软更新 τ=0.005 |

##### Level 3-B3: Local Computing TD3

| Level 4 子网络 | 结构 |
|---|---|
| Online Actor (`LocalComputingTD3Actor`) | 200→64(LN+ReLU)→64(LN+ReLU)→**1** [freq] |
| Online Critic - Dual-Q (`TD3Critic`) | (200+1)→64(LN+ReLU)→64(LN+ReLU)→1, ×2条 |
| Target Actor | 结构同 Online Actor，软更新 τ=0.005 |
| Target Critic - Dual-Q | 结构同 Online Critic，软更新 τ=0.005 |

---

#### Level 2-C: **Context-Aware Adaptive Noise Controller**（情境感知自适应噪声控制器）

| Level 3 逻辑分区 | 详细内容 |
|---|---|
| **输入因子 (5个)** | `queue_load`（队列负载 [0,1]）, `task_priority`（任务优先级 [0,1]）, `deadline_ratio`（剩余时间/截止时间 [0,1]）, `channel_quality`（信道质量 [0,1]）, `edge_load`（边缘节点负载 [0,1]）|
| **情境分类 (8种)** | ① `near_deadline`（接近截止, f=0.3）② `high_priority`（高优先级, f=0.4）③ `urgent_task`（紧急任务, f=0.4）④ `congested_network`（网络拥塞, f=0.7）⑤ `high_load`（高负载, f=0.8）⑥ `good_channel`（良好信道, f=0.3）⑦ `low_load`（低负载, f=0.3）⑧ `normal_task`（普通任务, f=0.6）|
| **3阶段机制** | **Phase 1 随机探索**: σ_global=0.5, 完全随机动作；**Phase 2 增强探索**: σ_global=0.35基础, 渐降；**Phase 3 稳定微调(Fine-tuning)**: σ_global 从0.25按衰减率0.99995持续衰减→最低0.1 |
| **阶段转换规则** | Phase 只升不降；Phase1→2: episode ≥ 100；Phase2→3: 成功率 ≥ 90% 且 Phase2至少持续50轮 |
| **噪声计算公式** | $\sigma_{final} = \sigma_{global} \times f_{context}$，clip到 $[0.1, 1.0]$ |
| **输出** | `noise_scale`(σ)、`deterministic_ratio`（控制双缓冲区采样比例）|

> ⚠️ **情境分类优先级顺序**（代码中 `classify_context()` 的 if-elif 顺序）：near_deadline > high_priority > urgent_task > congested_network > high_load > good_channel > low_load > normal_task（默认兜底）

---

#### Level 2-D: **Dual Replay Buffer**（双经验回放缓冲区）

| Level 3 组件 | 详细内容 |
|---|---|
| **B_E** (buffer_noisy / Exploratory) | 存储带探索噪声的经验，is_noisy=True |
| **B_D** (buffer_deterministic) | 存储确定性动作的经验，is_noisy=False |
| **Adaptive Sampling Ratio** | Phase1: B_D占比 0%；Phase2: 10%~20% 渐增；Phase3: 40% |
| **参数** | 容量 50,000；批大小 256；最小开始训练 2,000条 |
| **存储内容** | $(s_t, a_t, r_t, s_{t+1}, done, global\_state)$ |

---

#### Level 1-B: **V2X Task Offloading Environment**（环境，Agent 外部）

| Level 2 组成 | 说明 |
|---|---|
| Task Generation | 泊松到达(λ=0.2)，数据量0.5~3MB，CPU 0.5~3M cycles，截止时间100~200s |
| Network Model | V2I/V2V 信道，RSU×5，车辆×10，带宽1MHz |
| Queue Manager | HPC/LPC/ENC 多级队列 |
| Reward Calculation | 加权成本：时延(φ₁=0.1) + 能耗(φ₂=0.01) + 超时惩罚(φ₃=1.0) |
| **输出给 Agent** | 观测 $s_t$（200维）、奖励 $r_t$、终止标志 done、context_info（5个情境因子）|

---

### 1.3 完整嵌套层次树

```
Level 0: 整张架构图
│
├── Level 1: 【Hierarchical TD3 Agent】 ← 最大的框
│   │
│   ├── Level 2: 【High-Level TD3】 ← 指挥层
│   │   ├── Level 3: Online Actor (HighLevelTD3Actor)  →输出4维
│   │   │   └── Level 4: MLP 200→256→256→128→4 + LayerNorm
│   │   ├── Level 3: Online Critic (HighLevelTD3Critic) - Dual-Q
│   │   │   ├── Level 4: Q1 网络 (200+4)→256→256→1
│   │   │   └── Level 4: Q2 网络 (200+4)→256→256→1
│   │   ├── Level 3: Target Actor ← 软更新 τ=0.005
│   │   └── Level 3: Target Critic - Dual-Q ← 软更新 τ=0.005
│   │       ├── Level 4: Q1' 网络
│   │       └── Level 4: Q2' 网络
│   │
│   ├── Level 2: 【Low-Level TD3】 ← 执行层（3个并列子组）
│   │   │
│   │   ├── Level 3: 【V2I Scheduler TD3】
│   │   │   ├── Level 4: Online Actor (V2ISchedulerTD3Actor) →输出6维
│   │   │   ├── Level 4: Online Critic - Dual-Q (TD3Critic)
│   │   │   ├── Level 4: Target Actor ← 软更新 τ=0.005
│   │   │   └── Level 4: Target Critic - Dual-Q ← 软更新 τ=0.005
│   │   │
│   │   ├── Level 3: 【V2V Scheduler TD3】
│   │   │   ├── Level 4: Online Actor (V2VSchedulerTD3Actor) →输出6维
│   │   │   ├── Level 4: Online Critic - Dual-Q (TD3Critic)
│   │   │   ├── Level 4: Target Actor ← 软更新 τ=0.005
│   │   │   └── Level 4: Target Critic - Dual-Q ← 软更新 τ=0.005
│   │   │
│   │   └── Level 3: 【Local Computing TD3】
│   │       ├── Level 4: Online Actor (LocalComputingTD3Actor) →输出1维
│   │       ├── Level 4: Online Critic - Dual-Q (TD3Critic)
│   │       ├── Level 4: Target Actor ← 软更新 τ=0.005
│   │       └── Level 4: Target Critic - Dual-Q ← 软更新 τ=0.005
│   │
│   ├── Level 2: 【Context-Aware Adaptive Noise Controller】 ← 侧向辅助
│   │   ├── Level 3: 输入因子 (5个: queue_load, task_priority, deadline_ratio, channel_quality, edge_load)
│   │   ├── Level 3: 情境分类 (8种: near_deadline, high_priority, urgent_task, congested_network, high_load, good_channel, low_load, normal_task)
│   │   ├── Level 3: 3-Phase 阶段控制 (随机探索 → 增强探索 → 稳定微调Fine-tuning)
│   │   └── Level 3: 输出: noise_scale(σ), deterministic_ratio
│   │
│   └── Level 2: 【Dual Replay Buffer】 ← 底层支撑
│       ├── Level 3: B_E (Noisy Buffer / 探索性经验)
│       ├── Level 3: B_D (Deterministic Buffer / 确定性经验)
│       └── Level 3: Adaptive Sampling Ratio
│
└── Level 1: 【V2X Task Offloading Environment】 ← 独立大框，与Agent平级
    ├── Level 2: 状态观测 s_t (200-dim)
    ├── Level 2: 奖励 r_t
    ├── Level 2: 终止标志 done
    └── Level 2: context_info (queue_load, task_priority, deadline_ratio, channel_quality, edge_load)
```

---

## 二、所有模块内部构造详细清单

### 模块 ① — High-Level TD3 Actor 输出解析

> ⚠️ **网络输出维度 = 4**，语义决策 = 3（α、mode、p_base），其中 mode 由 2维 logits 经 Gumbel-Softmax 得到。

| 输出维度索引 | 变量名 | 激活函数 | 语义 | 值域 |
|:---:|---|---|---|---|
| `[0]` | α (alpha) | sigmoid | 任务卸载比例（卸载到边缘的比例）| [0, 1] |
| `[1]` | V2I_logit | 无（原始logits）| 卸载模式logit之一 | (-∞, +∞) |
| `[2]` | V2V_logit | 无（原始logits）| 卸载模式logit之一 | (-∞, +∞) |
| `[3]` | p_base (power) | sigmoid | 基础发射功率 | [0, 1] |

**Gumbel-Softmax 处理**（对 `[1:3]` 两维）：
- **训练时**：`F.gumbel_softmax(mode_logits, tau=temperature, hard=True)` → 可微分的 one-hot
- **推理时**：`argmax` → mode_idx: 0=V2I, 1=V2V

---

### 模块 ② — 各 Low-Level Actor 输出解析

| 低层组 | Actor输出维度 | 离散选择部分 | 连续输出部分 |
|---|:---:|---|---|
| **V2I** | 6 | `[0:5]` = 5个 RSU logits → Gumbel-Softmax → rsu_idx | `[5]` = power (sigmoid) |
| **V2V** | 6 | `[0:5]` = 5个 Neighbor logits → Gumbel-Softmax → neighbor_idx | `[5]` = power (sigmoid) |
| **Local** | 1 | 无 | `[0]` = freq (sigmoid) |

---

### 模块 ③ — Noise Controller 情境分类完整表

| # | 情境类型(代码变量名) | 中文含义 | 判定条件 | 噪声因子 f_context |
|:---:|---|---|---|:---:|
| 1 | `near_deadline` | 接近截止时间 | deadline_ratio < 0.3 | 0.3 |
| 2 | `high_priority` | 高优先级任务 | task_priority > 0.7 | 0.4 |
| 3 | `urgent_task` | 紧急任务 | task_priority > 0.5 且 deadline_ratio < 0.5 | 0.4 |
| 4 | `congested_network` | 网络拥塞 | edge_load > 0.8 | 0.7 |
| 5 | `high_load` | 系统高负载 | queue_load > 0.7 | 0.8 |
| 6 | `good_channel` | 良好信道 | channel_quality > 0.6 且 edge_load < 0.5 | 0.3 |
| 7 | `low_load` | 系统低负载 | queue_load < 0.3 | 0.3 |
| 8 | `normal_task` | 普通任务（默认兜底）| 以上均不满足 | 0.6 |

> 判定按 1→8 的 if-elif 优先级顺序，先命中者即返回。

---

### 模块 ④ — Noise Controller 3阶段机制详细参数

| 阶段 | 名称 | σ_global | 特殊行为 | 进入条件 | B_D 采样比例 |
|:---:|---|---|---|---|:---:|
| Phase 1 | 随机探索 (Random Exploration) | 0.5（固定）| `should_use_random_action()=True`，离散选择完全随机 | 初始默认 | 0% |
| Phase 2 | 增强探索 (Enhanced Exploration) | 0.35基础，随成功率渐降 | 噪声自适应调整 | episode ≥ 100 | 10%~20% |
| Phase 3 | 稳定微调 (Stable Fine-tuning) | 从0.25起，按衰减率0.99995持续衰减→最低0.1 | 噪声持续衰减不回升 | 成功率 ≥ 90%，且 Phase2 至少持续50轮 | 40% |

> **核心规则**：Phase 只升不降。即使成功率下降，已进入的 Phase 也不会回退。

---

### 模块 ⑤ — 噪声注入的精确缩放系数

> ⚠️ 代码中噪声注入并非简单的 σ·N(0,1)，不同动作维度有不同的缩放系数。

| 目标 | 噪声公式 (代码原文) | 含义 |
|---|---|---|
| **高层 α** | `N(0, σ × 1.5 × 0.2)` | 高层增强系数1.5 × α缩放0.2 |
| **高层 p_base** | `N(0, σ × 1.5 × 0.1)` | 高层增强系数1.5 × power缩放0.1 |
| **高层 mode** | Phase1 时完全随机 `randint(0,2)`；Phase2/3 无额外噪声（Gumbel-Softmax 自身提供随机性）| — |
| **低层 V2I power** | `N(0, σ × 0.1)` | 低层power缩放0.1 |
| **低层 V2V power** | `N(0, σ × 0.1)` | 同上 |
| **低层 Local freq** | `N(0, σ × 0.1)` | 低层freq缩放0.1 |
| **低层 V2I rsu选择** | Phase1 时 `randint(0, NUM_RSU)`；否则无额外噪声 | — |
| **低层 V2V neighbor选择** | Phase1 时 `randint(0, 5)`；否则无额外噪声 | — |

---

### 模块 ⑥ — TD3 更新机制（各层共享逻辑）

| 项目 | 参数值 | 代码来源 |
|---|---|---|
| **Dual-Q** | $Q_{target} = \min(Q_1, Q_2)$ 减少过估计 | `torch.min(target_q1, target_q2)` |
| **延迟策略更新** | Critic 每步更新，Actor 每 **2** 步更新 (d=2) | `policy_delay=2` |
| **目标策略平滑** | $a' = \mu_{target}(s') + \text{clip}(\epsilon, -0.5, 0.5)$，$\epsilon \sim \mathcal{N}(0, 0.2)$ | `policy_noise=0.2, noise_clip=0.5` |
| **软更新** | $\theta' \leftarrow 0.005 \cdot \theta + 0.995 \cdot \theta'$ | `tau=0.005` |
| **折扣因子** | γ = 0.99 | `gamma=0.99` |
| **梯度裁剪** | 高层 max_grad_norm = 0.5 | `max_grad_norm=0.5` |
| **优化器** | Adam，lr = 3e-4（高层/低层统一）| `learning_rate=3e-4` |
| **学习率衰减** | episode 500 起开始衰减，持续 1000 轮，最低到初始的 10% | `lr_decay_start=500` |

---

### 模块 ⑦ — 网络总数量汇总

| 类别 | Online Actor | Online Critic (含Q1+Q2) | Target Actor | Target Critic (含Q1+Q2) | 小计 |
|---|:---:|:---:|:---:|:---:|:---:|
| High-Level | 1 | 1 | 1 | 1 | **4** |
| V2I | 1 | 1 | 1 | 1 | **4** |
| V2V | 1 | 1 | 1 | 1 | **4** |
| Local | 1 | 1 | 1 | 1 | **4** |
| **合计** | **4** | **4** | **4** | **4** | **16个子网络** |

---

## 三、所有箭头连接清单（标注层次关系 + 精确内容）

### A. 跨顶层模块的箭头（Environment ↔ Agent）

| # | 起点 | → | 终点 | 传递内容 | 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| A1 | Environment | → | High-Level Actor | $s_t$ (200维局部观测) | L1→L1内L3 | 实线 |
| A2 | 动作组合 (Agent内) | → | Environment | Combined Action $a_t$ | L1内→L1 | **实线(粗)** |
| A3 | Environment | → | Dual Replay Buffer | $(s_t, a_t, r_t, s_{t+1}, done)$ | L1→L1内L2 | 实线 |
| A4 | Environment | → | Noise Controller | context_info: {queue_load, task_priority, deadline_ratio, channel_quality, edge_load} | L1→L1内L2 | 虚线 |

---

### B. Agent内部：High-Level → Low-Level（层级指挥，分层核心）

| # | 起点 | → | 终点 | 传递内容 | 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| B1 | High-Level Actor | → | V2I Actor | $s_t$ + 激活信号（当 mode_idx=0，即 V2I 模式）| L2→L2(L3) | 实线(条件标注 `mode=V2I`) |
| B2 | High-Level Actor | → | V2V Actor | $s_t$ + 激活信号（当 mode_idx=1，即 V2V 模式）| L2→L2(L3) | 实线(条件标注 `mode=V2V`) |
| B3 | High-Level Actor | → | Local Actor | $s_t$ + 激活信号（当 α<0.01 纯本地，或 α<0.99 时作为混合计算补充）| L2→L2(L3) | 实线(条件标注 `α<0.01 or 混合`) |

> ⚠ 这是 **分层架构的核心箭头**：High-Level 做宏观决策 (α, mode, p_base)，然后根据 mode_idx **路由** 给对应的 Low-Level 去执行细粒度决策。

---

### C. Agent内部：各 Actor → 动作组合（汇聚输出）

| # | 起点 | → | 终点 | 传递内容 | 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| C1 | High-Level Actor | → | 动作组合 | α, mode_idx, p_base | L3→汇聚 | 实线 |
| C2 | V2I Actor | → | 动作组合 | rsu_idx, power | L4→汇聚 | 实线 |
| C3 | V2V Actor | → | 动作组合 | neighbor_idx, power | L4→汇聚 | 实线 |
| C4 | Local Actor | → | 动作组合 | freq | L4→汇聚 | 实线 |

---

### D. Noise Controller → 各 Actor 输出（噪声注入，侧向辅助）

| # | 起点 | → | 终点 | 传递内容（精确缩放系数）| 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| D1 | Noise Controller | → | High-Level Actor 输出(α) | $\alpha \mathrel{+}= \mathcal{N}(0,\; \sigma \times 1.5 \times 0.2)$ | L2→L2内L3 | 虚线(彩色) |
| D2 | Noise Controller | → | High-Level Actor 输出(p_base) | $p_{base} \mathrel{+}= \mathcal{N}(0,\; \sigma \times 1.5 \times 0.1)$ | L2→L2内L3 | 虚线(彩色) |
| D3 | Noise Controller | → | V2I Actor 输出(power) | $power \mathrel{+}= \mathcal{N}(0,\; \sigma \times 0.1)$ | L2→L3内L4 | 虚线(彩色) |
| D4 | Noise Controller | → | V2V Actor 输出(power) | $power \mathrel{+}= \mathcal{N}(0,\; \sigma \times 0.1)$ | L2→L3内L4 | 虚线(彩色) |
| D5 | Noise Controller | → | Local Actor 输出(freq) | $freq \mathrel{+}= \mathcal{N}(0,\; \sigma \times 0.1)$ | L2→L3内L4 | 虚线(彩色) |
| D6 | Noise Controller | → | Dual Replay Buffer | deterministic_ratio（控制 B_E/B_D 采样比例）| L2→L2 | 虚线 |

---

### E. Dual Replay Buffer → 各 Critic（训练数据流）

| # | 起点 | → | 终点 | 传递内容 | 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| E1 | Dual Replay Buffer | → | High-Level Critic | sampled batch (s, a, r, s', done) | L2→L2内L3 | 实线 |
| E2 | Dual Replay Buffer | → | V2I Critic | sampled batch | L2→L3内L4 | 实线 |
| E3 | Dual Replay Buffer | → | V2V Critic | sampled batch | L2→L3内L4 | 实线 |
| E4 | Dual Replay Buffer | → | Local Critic | sampled batch | L2→L3内L4 | 实线 |

---

### F. 各 TD3 组内部训练闭环（每组5条，共4组=20条）

以下箭头在 **High-Level / V2I / V2V / Local** 四组内各自独立存在：

| # | 起点 | → | 终点 | 传递内容 | 线型 |
|:---:|---|---|---|---|---|
| F1 | Target Actor | → | Target Critic | 目标动作 $a' = \mu_{target}(s')$，经目标策略平滑：$a' + \text{clip}(\mathcal{N}(0, 0.2),\; -0.5,\; 0.5)$ | 虚线 |
| F2 | Target Critic | → | Online Critic | TD目标 $y = r + 0.99 \times (1-done) \times \min(Q_1', Q_2')$ → MSE Loss | 虚线 |
| F3 | Online Critic (Q1) | → | Online Actor | 策略梯度 $\nabla_\theta \left[-Q_1(s, \mu_\theta(s))\right]$（**每2步执行1次**）| 虚线(反向) |
| F4 | Online Actor | ⇢ | Target Actor | 软更新 $\theta' \leftarrow 0.005\theta + 0.995\theta'$ | **点线** |
| F5 | Online Critic | ⇢ | Target Critic | 软更新 $\theta' \leftarrow 0.005\theta + 0.995\theta'$ | **点线** |

> **[X]** = High-Level / V2I / V2V / Local，四组各自独立闭环，**共 4×5 = 20 条**组内训练箭头

---

### G. 训练统计反馈

| # | 起点 | → | 终点 | 传递内容 | 层次关系 | 线型 |
|:---:|---|---|---|---|---|---|
| G1 | 训练过程 (每episode结束) | → | Noise Controller | (episode编号, is_success) → 更新成功率 → 触发Phase升级 | →L2 | 虚线 |

---

### H. 双缓冲区内部数据流

| # | 起点 | → | 终点 | 传递内容 | 线型 |
|:---:|---|---|---|---|---|
| H1 | 经验入口(带噪声动作) | → | B_E (buffer_noisy) | is_noisy=True 的经验 | 实线 |
| H2 | 经验入口(确定性动作) | → | B_D (buffer_deterministic) | is_noisy=False 的经验 | 实线 |
| H3 | B_E + B_D | → | 采样输出 batch | 按 deterministic_ratio 混合采样 | 实线 |

---

## 四、箭头总汇总

| 类别 | 箭头数量 | 说明 |
|---|:---:|---|
| A. 环境 ↔ 智能体 | 4 | 跨顶层模块 (L1↔L1) |
| B. 高层 → 低层（层级指挥）| 3 | **分层核心** (L2→L2) |
| C. 各 Actor → 动作组合 | 4 | 汇聚输出 |
| D. 噪声控制器 → 各处 | 6 | 侧向辅助（含精确缩放系数）|
| E. 缓冲区 → 各 Critic | 4 | 训练数据供给 |
| F. 各组内部训练闭环 | 4×5=20 | TD3 机制 |
| G. 训练统计反馈 | 1 | Phase 更新 |
| H. 双缓冲区内部 | 3 | 经验存储与采样 |
| **总计** | **45条** | — |

---

## 五、图中推荐的线型约定

| 线型 | 含义 | 对应箭头编号 |
|---|---|---|
| **实线箭头** ─→ | 数据正向流动（推理/执行阶段）| A1–A3, B1–B3, C1–C4, E1–E4, H1–H3 |
| **虚线箭头** ‐‐→ | 训练信号 / 辅助控制信号 | A4, D1–D6, F1–F3, G1 |
| **点线箭头** ⋯⇢ | 软更新 (τ=0.005) | F4–F5（×4组=8条）|
| **条件分支** (带文字标注) | 模式路由 | B1(`mode=V2I`), B2(`mode=V2V`), B3(`α<0.01`) |
| **粗实线箭头** ═→ | 组合动作返回环境 | A2 |

---

## 六、勘误说明

> 以下为本文档 v3.0 修正的重要问题：

| 问题 | 旧值 | 修正后（与代码一致）|
|---|---|---|
| Context Types 数量 | 仅列5种(normal, high_load, good_channel, near_deadline, high_priority) | **完整8种**: near_deadline, high_priority, urgent_task, congested_network, high_load, good_channel, low_load, normal_task |
| `normal` 命名 | `normal` | `normal_task`（代码变量名）|
| 高层 action_dim | config注释写 `action_dim: 3` | 网络硬编码输出 **4维** [α, V2I_logit, V2V_logit, p_base]，"3个语义决策"是因为 mode_logits(2维) 只产生1个离散选择 |
| 输入因子变量名 | "Deadline Proximity" | `deadline_ratio`（代码变量名：剩余时间/截止时间）|
| Phase 3 名称 | "Stable" | **稳定微调 (Stable Fine-tuning)**（代码注释原文）|
| 噪声注入公式 | 简写 σ·N(0,1) | 不同动作维度有不同缩放：高层 σ×1.5×0.2(α)/σ×1.5×0.1(power)；低层 σ×0.1(power/freq) |